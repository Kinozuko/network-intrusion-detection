# -*- coding: utf-8 -*-
"""nid.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1omTEYcbPcWe46uSGH1YlXHAN-4aw63xL

# Network Instrusion Detection

##Installing dependecies

For this project we need install [Feature Selector](https://github.com/WillKoehrsen/feature-selector/blob/master/Feature%20Selector%20Usage.ipynb). After installing you need to restart runtime of the notebook.
"""

!pip install feature-selector

"""##Importing libraries"""

import joblib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from feature_selector import FeatureSelector
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import f1_score
from sklearn.metrics import classification_report
from sklearn.metrics import roc_auc_score

"""## Exporting Data

**Remember to use the path where you store the dataset**
"""

df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Network Instrusion Detection/data/dataset.csv')

"""Let's see a quick look to the dataset"""

df.head()

"""##Preprocessing Data

We gonna select feature, for this we need the separate the ***class*** column and dropping from dataframe
"""

df_label = df['class']
df.drop(columns=['class'],inplace=True)
df_label.head()

"""##Feature Selector

Now, it's time to select the correct features of this dataset, for this purpose let's use [Feature Selector](https://github.com/WillKoehrsen/feature-selector/blob/master/Feature%20Selector%20Usage.ipynb)

**Feature selector has five functions for identifying columns to remove:**



*   **identify_missing**
*   **identify_single_unique**
*   **identify_collinear**
*   **identify_zero_importance**
*   **identify_low_importance**

In this notebook we will test all the five function, to start we need to create an instance.

***Examples on how to use Feature Selector are in the end of this notebook***
"""

fs = FeatureSelector(data = df, labels = df_label)

"""###Removing Features

***Once we have identified the features to remove, we have a number of ways to drop the features. We can access any of the feature lists in the removal_ops dictionary and remove the columns manually. We also can use the remove method, passing in the methods that identified the features we want to remove***

Now, we will apply collinear, zero importance, low importance and sigle unique feature importance to selecti which columns to remove
"""

fs.identify_collinear(correlation_threshold=0.975)

fs.identify_zero_importance(task = 'classification', eval_metric = 'auc', 
                            n_iterations = 10, early_stopping = True)

fs.identify_low_importance(cumulative_importance = 0.99)

fs.identify_single_unique()

to_remove = fs.check_removal()

feature_df = fs.remove(
    methods = ['collinear', 'zero_importance', 'low_importance', 'single_unique'],
    keep_one_hot=False
)

feature_df.head()

category_columns = [
                    'protocol_type',
                    'service',
                    'flag'
]

feature_df[category_columns] = feature_df[category_columns].astype('category')

categories = {
    'protocol_type' : feature_df.protocol_type.cat.categories,
    'service' : feature_df.service.cat.categories,
    'flag' : feature_df.flag.cat.categories
}

feature_df.protocol_type = feature_df.protocol_type.cat.codes
feature_df.service = feature_df.service.cat.codes
feature_df.flag = feature_df.flag.cat.codes
feature_df.head()

feature_df = feature_df.astype(float)

feature_df.head()

"""##Splitting Dataset

After selecting features, we have our dataset (***feature_df***) and our labels (***df_label***)
"""

(feature_df.head(),df_label.head())

"""We split our dataset to 90% to train and 10% to test"""

X_train, X_test, y_train, y_test = train_test_split(feature_df, df_label,test_size=0.10)

"""##Model

In this step we will train three different models:

* Navie-Bayes
* Linear SVC
* K-Neighbors

###Naive-Bayes
"""

gnb = GaussianNB()

gnb_model = gnb.fit(X_train, y_train)

gnb_pred = gnb_model.predict(X_test)

"""####Evaluate Model

#####Confusion Matrix

The confusion matrix will be represented as:

> $\begin{pmatrix}
 TN & FP \\
  FN & TP
 \end{pmatrix}$
"""

confusion_matrix(y_test, gnb_pred)

"""Acurracy score can be calculated as:

> $ \textrm{Accuracy} = \frac{\textrm{Number of correct predictions}}{\textrm{Total number of predictions}}$
"""

accuracy_score(y_test, gnb_pred)

"""Recall can be calculated as:

> $\textrm{Recall} = \frac{TP}{TP+FN}$
"""

recall_score(y_test, gnb_pred, average=None)

"""Precision can be calculated as:

> $\textrm{Precision} = \frac{TP}{TP+FP}$
"""

precision_score(y_test, gnb_pred, average=None)

"""#####F1 Score

F1 score can be calculated as:

> $F1 = \frac{2*\textrm{precision}*\textrm{recall}}{\textrm{precision}+\textrm{recall}}$
"""

f1_score(y_test, gnb_pred, average=None)

"""#####Classification Report

Also we can print a report for this classification problem
"""

print(classification_report(y_test, gnb_pred, target_names=df_label.unique()))

"""#####AUC-ROC"""

roc_auc_score(
    y_test.astype('category').cat.codes,
    pd.Series(gnb_pred).astype('category').cat.codes
)

"""###LinearSVC"""

linear = LinearSVC(random_state=0,max_iter=100)

svc_model = linear.fit(X_train, y_train)

svc_pred = svc_model.predict(X_test)

"""####Evaluate Model

#####Confusion Matrix

The confusion matrix will be represented as:

> $\begin{pmatrix}
 TN & FP \\
  FN & TP
 \end{pmatrix}$
"""

confusion_matrix(y_test, svc_pred)

"""Acurracy score can be calculated as:

> $ \textrm{Accuracy} = \frac{\textrm{Number of correct predictions}}{\textrm{Total number of predictions}}$
"""

accuracy_score(y_test, svc_pred)

"""Recall can be calculated as:

> $\textrm{Recall} = \frac{TP}{TP+FN}$
"""

recall_score(y_test, svc_pred, average=None)

"""Precision can be calculated as:

> $\textrm{Precision} = \frac{TP}{TP+FP}$
"""

precision_score(y_test, svc_pred, average=None)

"""#####F1 Score

F1 score can be calculated as:

> $F1 = \frac{2*\textrm{precision}*\textrm{recall}}{\textrm{precision}+\textrm{recall}}$
"""

f1_score(y_test, svc_pred, average=None)

"""#####Classification Report

Also we can print a report for this classification problem
"""

print(classification_report(y_test, svc_pred, target_names=df_label.unique()))

"""#####AUC-ROC"""

roc_auc_score(
    y_test.astype('category').cat.codes,
    pd.Series(svc_pred).astype('category').cat.codes
)

"""###K-Neighbors"""

neigh = KNeighborsClassifier(n_neighbors=2)

neigh.fit(X_train, y_train)

neihg_pred = neigh.predict(X_test)

"""####Evaluate Model

#####Confusion Matrix

The confusion matrix will be represented as:

> $\begin{pmatrix}
 TN & FP \\
  FN & TP
 \end{pmatrix}$
"""

confusion_matrix(y_test, neihg_pred)

"""Acurracy score can be calculated as:

> $ \textrm{Accuracy} = \frac{\textrm{Number of correct predictions}}{\textrm{Total number of predictions}}$
"""

accuracy_score(y_test, neihg_pred)

"""Recall can be calculated as:

> $\textrm{Recall} = \frac{TP}{TP+FN}$
"""

recall_score(y_test, neihg_pred, average=None)

"""Precision can be calculated as:

> $\textrm{Precision} = \frac{TP}{TP+FP}$
"""

precision_score(y_test, neihg_pred, average=None)

"""#####F1 Score

F1 score can be calculated as:

> $F1 = \frac{2*\textrm{precision}*\textrm{recall}}{\textrm{precision}+\textrm{recall}}$
"""

f1_score(y_test, neihg_pred, average=None)

"""#####Classification Report

Also we can print a report for this classification problem
"""

print(classification_report(y_test, neihg_pred, target_names=df_label.unique()))

"""#####AUC-ROC"""

roc_auc_score(
    y_test.astype('category').cat.codes,
    pd.Series(neihg_pred).astype('category').cat.codes
)

"""##Importing Model

We will import the three models for practice purpose
"""

joblib.dump(gnb_model,'gnb_model')

joblib.dump(svc_model,'svc_model')

joblib.dump(neigh,'neigh_model')

"""#How to use Feature Selector

The following five sections are example on how to use feature-importance

##Collinear (highly correlated)

**This method finds pairs of collinear features based on the Pearson correlation coefficient. For each pair above the specified threshold (in terms of absolute value), it identifies one of the variables to be removed**
"""

fs.identify_collinear(correlation_threshold=0.975)

"""The method by default doesn't one-hot encode the data, so it only take numeric values, in case you want one-hot encode data use ***one_hot=True***"""

fs.identify_collinear(correlation_threshold=0.975, one_hot=True)

"""Now we can see which features have a strong correlation"""

fs.ops['collinear']

"""***We can view a heatmap of the correlations above the threhold. The features which will be dropped are on the x-axis***"""

fs.plot_collinear()

"""**To plot all of the correlations in the data, we can pass in plot_all = True to the plot_collinear function**"""

fs.plot_collinear(plot_all=True)

"""Now let's see details of correlation. ***The drop_feature will be removed and for each feature that will be removed, there may be several correlations it has with the corr_feature that are above the correlation_threshold***"""

fs.record_collinear.head()

"""##Zero Importance

**This method relies on a machine learning model to identify features to remove. It therefore requires a supervised learning problem with labels. The method works by finding feature importances using a gradient boosting machine**
"""

fs.identify_zero_importance(task = 'classification', eval_metric = 'auc', 
                            n_iterations = 10, early_stopping = True)

"""***Running the gradient boosting model requires one hot encoding the features. These features are saved in the one_hot_features attribute of the FeatureSelector. The original features are saved in the base_features***"""

print(len(fs.one_hot_features))
print(len(fs.base_features))

"""***The data attribute of the FeatureSelector holds the original dataframe. After one-hot encoding, the data_all attribute holds the original data plus the one-hot encoded features***"""

fs.data_all

"""***There are a number of methods we can use to inspect the results of the feature importances. First we can access the list of features with zero importance***"""

fs.ops['zero_importance']

fs.plot_feature_importances(threshold = 0.99, plot_n = 20)

"""**All of the feature importances are accessible in the feature_importances attribute of the FeatureSelector**"""

fs.feature_importances

"""##Low Importance

***This method builds off the feature importances from the gradient boosting machine (identify_zero_importance must be run first) by finding the lowest importance features not needed to reach a specified cumulative total feature importance***

***When using this method, we must have already run identify_zero_importance and need to pass in a cumulative_importance that accounts for that fraction of total feature importance***
"""

fs.identify_low_importance(cumulative_importance = 0.99)

"""***The low importance features to remove are those that do not contribute to the specified cumulative importance. These are also available in the ops dictionary***"""

fs.ops['low_importance']

"""##Single Unique Value

***The next method is straightforward: find any features that have only a single unique value.***
"""

fs.identify_single_unique()

"""Now we can see which features have a single value"""

fs.ops['single_unique']

"""Let's plot the number of unique values in each feature of the dataset"""

fs.plot_unique()

"""If you want a detailed information use"""

fs.unique_stats

"""##Missing Values

***The first feature selection method is straightforward: find any columns with a missing fraction greater than a specified threshold.***

In this example we will use a threshold of 0.7 which mean to finding features with more than 70% of missing values.

***In these datasets there is no lack of data, so in this case it is just showing how the function would work***
"""

fs.identify_missing(missing_threshold=0.7)

"""In case some features can be removed, you can see them as follows"""

fs.ops['missing']

"""Also, we can plot the result"""

fs.plot_missing()

"""If you want a detailed information use"""

fs.missing_stats